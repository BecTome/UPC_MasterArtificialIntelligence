{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Lexical Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following (lemma, category) pairs:\n",
    "\n",
    "```\n",
    "(’the’,’DT’), (’man’,’NN’), (’swim’,’VB’), (’with’, ’PR’), (’a’, ’DT’),\n",
    "(’girl’,’NN’), (’and’, ’CC’), (’a’, ’DT’), (’boy’, ’NN’), (’whilst’, ’PR’),\n",
    "(’the’, ’DT’), (’woman’, ’NN’), (’walk’, ’VB’)\n",
    "```\n",
    "- For each pair, when possible, print their most frequent WordNet synset\n",
    "\n",
    "- For each pair of words, when possible, print their corresponding least common subsumer (LCS) and their similarity value, using the following functions:\n",
    "\n",
    "    - Path Similarity\n",
    "\n",
    "    - Leacock-Chodorow Similarity\n",
    "\n",
    "    - Wu-Palmer Similarity\n",
    "\n",
    "    - Lin Similarity\n",
    "\n",
    "Normalize similarity values when necessary. What similarity seems better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\alber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\alber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet_ic')\n",
    "\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's recall how each of the distances are calculated. It's important to find boundaries for them so that it's possible to make some transforms in order to take them to the \n",
    "$[0, 1]$ interval so  that all of them are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shortest Path Length**: \n",
    "$$\n",
    "Sim(s1,s2) = \\dfrac{1}{SPL(s1,s2)}\n",
    "$$\n",
    "\n",
    "where SPL(s1,s2) is the Shortest Path Length from s1 to s2 as vertex-countings (similarity of a word and itself is 1) so that \n",
    "\n",
    "$$\n",
    "0 < Sim(s1,s2) \\leq 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leacock & Chodorow**: \n",
    "\n",
    "$$\n",
    "Sim(s1,s2) = −\\log{\\dfrac{SPL(s1,s2)}{2·MaxDepth}}\n",
    "$$\n",
    "\n",
    "where depth(s) = SPL(TopSynset,s) and $MaxDepth = \\max_{s\\in WN}depth(s)$\n",
    "\n",
    "It is possible to show that there's a maximum value for the similarity of two synsets, which is $\\log{2·MaxDepth}$\n",
    "\n",
    "$$\n",
    "Sim(s1,s2) = −\\log{\\dfrac{SPL(s1,s2)}{2·MaxDepth}} = -\\log{SPL(s1,s2)} + \\log{(2MaxDepth)} \\leq \\log(2MaxDepth)\n",
    "$$\n",
    "\n",
    "so that\n",
    "\n",
    "$$\n",
    "0 < \\dfrac{Sim(s1,s2)}{\\log\\left(2MaxDepth\\right)} \\leq 1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max depth is 20 and the normalization value is 3.6888794541139363\n"
     ]
    }
   ],
   "source": [
    "max_depth = max(max(len(hyp_path) for hyp_path in ss.hypernym_paths()) for ss in wn.all_synsets())\n",
    "norm_value = np.log(2 * max_depth)\n",
    "\n",
    "print(f\"The max depth is {max_depth} and the normalization value is {norm_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wu & Palmer**:\n",
    "\n",
    "$$\n",
    "Sim(s1,s2) = \\dfrac{2*depth(LCS(s1,s2))}{depth_{LCS(s1,s2)}(s1)+depth_{LCS(s1,s2)}(s2)}\n",
    "$$\n",
    "\n",
    "where LCS(s1,s2) = Lowest Common Subsumer of s1 and s2 and $depth_{s'}(s) = SPL(TopSynset,s)$ through s'\n",
    "\n",
    "so the highest similarity would be when $depth_{LCS(s1,s2)}(s1)=depth_{LCS(s1,s2)}(s2)$, which is when s1 and s2 are siblings and $depth(LCS(s1,s2)) = maxDepth$. So the maximum value for the similarity of two synsets is 1.\n",
    "\n",
    "\n",
    "**Lin**: \n",
    "\n",
    "$$\n",
    "Sim(s1,s2) = \\dfrac{2*IC(LCS(s1,s2))}{IC(s1)+IC(s2)}\n",
    "$$\n",
    "\n",
    "where $IC(s) = −log_2(P(s))$ = information content of s (from frequencies in a corpus)\n",
    "\n",
    "In the case of Lin, the maximum value for the similarity of two synsets is 1 (when $IC(s1)=IC(s2)$ and $IC(LCS(s1,s2)) = IC(s1) = IC(s2)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Frequent Wordnet Synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided sample needs to be processed so that the POS tags are in the necessary format for Wordnet synsets getter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 'n'),\n",
       " ('swim', 'v'),\n",
       " ('girl', 'n'),\n",
       " ('boy', 'n'),\n",
       " ('woman', 'n'),\n",
       " ('walk', 'v')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the pairs and discard the ones that do not have a POS tag\n",
    "ls_pairs = [('the','DT'), ('man','NN'), ('swim','VB'), ('with', 'PR'), ('a', 'DT'),\n",
    "            ('girl','NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'),\n",
    "            ('the', 'DT'), ('woman', 'NN'), ('walk', 'VB')]\n",
    "\n",
    "d_wn_pos = {'NN': wn.NOUN, 'VB': wn.VERB, 'JJ': wn.ADJ, 'RB': wn.ADV}\n",
    "ls_pairs_wn = [(pair[0], d_wn_pos.get(pair[1])) for pair in ls_pairs if pair[1] in d_wn_pos]\n",
    "ls_pairs_wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the sample is processed, the closest synset for each of them is calculated. Given Wordnet lexical structure, this means the first synset in the list obtained after calling `wordnet.synsets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'man': Synset('man.n.01'),\n",
       " 'swim': Synset('swim.v.01'),\n",
       " 'girl': Synset('girl.n.01'),\n",
       " 'boy': Synset('male_child.n.01'),\n",
       " 'woman': Synset('woman.n.01'),\n",
       " 'walk': Synset('walk.v.01')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_synsets(ls_pairs_wn):\n",
    "    '''\n",
    "    Calculate the closest synset for each word in the list of pairs\n",
    "    '''\n",
    "    d_synsets = {}\n",
    "    for pair in ls_pairs_wn:\n",
    "        synsets = wn.synsets(pair[0], pair[1])\n",
    "        if synsets:\n",
    "            d_synsets[pair[0]] = synsets[0]\n",
    "        else:\n",
    "            d_synsets[pair[0]] = None\n",
    "    return d_synsets\n",
    "\n",
    "d_synsets = get_synsets(ls_pairs_wn)\n",
    "d_synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get LCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lowest Common Subsummer (LCS) of a given pair of synsets is the first common parent of both synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>lcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('male.n.02')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('travel.v.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('male.n.02')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('travel.v.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        word1                      word2  \\\n",
       "0          Synset('man.n.01')        Synset('swim.v.01')   \n",
       "1          Synset('man.n.01')        Synset('girl.n.01')   \n",
       "2          Synset('man.n.01')  Synset('male_child.n.01')   \n",
       "3          Synset('man.n.01')       Synset('woman.n.01')   \n",
       "4          Synset('man.n.01')        Synset('walk.v.01')   \n",
       "5         Synset('swim.v.01')         Synset('man.n.01')   \n",
       "6         Synset('swim.v.01')        Synset('girl.n.01')   \n",
       "7         Synset('swim.v.01')  Synset('male_child.n.01')   \n",
       "8         Synset('swim.v.01')       Synset('woman.n.01')   \n",
       "9         Synset('swim.v.01')        Synset('walk.v.01')   \n",
       "10        Synset('girl.n.01')         Synset('man.n.01')   \n",
       "11        Synset('girl.n.01')        Synset('swim.v.01')   \n",
       "12        Synset('girl.n.01')  Synset('male_child.n.01')   \n",
       "13        Synset('girl.n.01')       Synset('woman.n.01')   \n",
       "14        Synset('girl.n.01')        Synset('walk.v.01')   \n",
       "15  Synset('male_child.n.01')         Synset('man.n.01')   \n",
       "16  Synset('male_child.n.01')        Synset('swim.v.01')   \n",
       "17  Synset('male_child.n.01')        Synset('girl.n.01')   \n",
       "18  Synset('male_child.n.01')       Synset('woman.n.01')   \n",
       "19  Synset('male_child.n.01')        Synset('walk.v.01')   \n",
       "20       Synset('woman.n.01')         Synset('man.n.01')   \n",
       "21       Synset('woman.n.01')        Synset('swim.v.01')   \n",
       "22       Synset('woman.n.01')        Synset('girl.n.01')   \n",
       "23       Synset('woman.n.01')  Synset('male_child.n.01')   \n",
       "24       Synset('woman.n.01')        Synset('walk.v.01')   \n",
       "25        Synset('walk.v.01')         Synset('man.n.01')   \n",
       "26        Synset('walk.v.01')        Synset('swim.v.01')   \n",
       "27        Synset('walk.v.01')        Synset('girl.n.01')   \n",
       "28        Synset('walk.v.01')  Synset('male_child.n.01')   \n",
       "29        Synset('walk.v.01')       Synset('woman.n.01')   \n",
       "\n",
       "                      lcs  \n",
       "0                    None  \n",
       "1    Synset('adult.n.01')  \n",
       "2     Synset('male.n.02')  \n",
       "3    Synset('adult.n.01')  \n",
       "4                    None  \n",
       "5                    None  \n",
       "6                    None  \n",
       "7                    None  \n",
       "8                    None  \n",
       "9   Synset('travel.v.01')  \n",
       "10   Synset('adult.n.01')  \n",
       "11                   None  \n",
       "12  Synset('person.n.01')  \n",
       "13   Synset('woman.n.01')  \n",
       "14                   None  \n",
       "15    Synset('male.n.02')  \n",
       "16                   None  \n",
       "17  Synset('person.n.01')  \n",
       "18  Synset('person.n.01')  \n",
       "19                   None  \n",
       "20   Synset('adult.n.01')  \n",
       "21                   None  \n",
       "22   Synset('woman.n.01')  \n",
       "23  Synset('person.n.01')  \n",
       "24                   None  \n",
       "25                   None  \n",
       "26  Synset('travel.v.01')  \n",
       "27                   None  \n",
       "28                   None  \n",
       "29                   None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lcs(syn1, syn2):\n",
    "    '''\n",
    "    Get the lowest common subsummer between two synsets\n",
    "    '''\n",
    "    return syn1.lowest_common_hypernyms(syn2)\n",
    "\n",
    "def get_all_lcs(ls_pairs_wn):\n",
    "    '''\n",
    "    Input: list of pairs of words with their POS tag\n",
    "    output: dictionary with the pairs as keys and the lowest common synset as values\n",
    "    '''\n",
    "    ls_pairs_comb = [c for c in list(product(ls_pairs_wn, ls_pairs_wn)) if len(c) == 2 and c[0] != c[1]]\n",
    "    ls_d_pairs_comb = [get_synsets(comb) for comb in ls_pairs_comb]\n",
    "    d_lcs = {tuple(d.values()): get_lcs(*list(d.values())) for d in ls_d_pairs_comb}\n",
    "    return d_lcs\n",
    "\n",
    "d_lcs_ = get_all_lcs(ls_pairs_wn)\n",
    "\n",
    "df = pd.DataFrame(d_lcs_.values(), index=d_lcs_.keys(), columns=['lcs']).reset_index()\n",
    "df.rename(columns={'level_0': 'word1', 'level_1':'word2'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the not normalized similarity values are calculated for each of the pairs of synsets. The similarity values are calculated using the four different methods described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>lcs</th>\n",
       "      <th>path_sim</th>\n",
       "      <th>lch_sim</th>\n",
       "      <th>wup_sim</th>\n",
       "      <th>lin_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.906780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.906780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('travel.v.01')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.159484</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.491005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('travel.v.01')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.159484</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.491005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.845827</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.292728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.845827</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.292728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.028148</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.318423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.028148</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.318423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('male.n.02')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.538974</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.729472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('male.n.02')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.538974</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.729472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.251292</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.713511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.538974</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.787084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.251292</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.713511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.538974</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.787084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        word1                      word2  \\\n",
       "13        Synset('girl.n.01')       Synset('woman.n.01')   \n",
       "22       Synset('woman.n.01')        Synset('girl.n.01')   \n",
       "9         Synset('swim.v.01')        Synset('walk.v.01')   \n",
       "26        Synset('walk.v.01')        Synset('swim.v.01')   \n",
       "12        Synset('girl.n.01')  Synset('male_child.n.01')   \n",
       "17  Synset('male_child.n.01')        Synset('girl.n.01')   \n",
       "18  Synset('male_child.n.01')       Synset('woman.n.01')   \n",
       "23       Synset('woman.n.01')  Synset('male_child.n.01')   \n",
       "2          Synset('man.n.01')  Synset('male_child.n.01')   \n",
       "15  Synset('male_child.n.01')         Synset('man.n.01')   \n",
       "1          Synset('man.n.01')        Synset('girl.n.01')   \n",
       "3          Synset('man.n.01')       Synset('woman.n.01')   \n",
       "10        Synset('girl.n.01')         Synset('man.n.01')   \n",
       "20       Synset('woman.n.01')         Synset('man.n.01')   \n",
       "0          Synset('man.n.01')        Synset('swim.v.01')   \n",
       "4          Synset('man.n.01')        Synset('walk.v.01')   \n",
       "5         Synset('swim.v.01')         Synset('man.n.01')   \n",
       "6         Synset('swim.v.01')        Synset('girl.n.01')   \n",
       "7         Synset('swim.v.01')  Synset('male_child.n.01')   \n",
       "8         Synset('swim.v.01')       Synset('woman.n.01')   \n",
       "11        Synset('girl.n.01')        Synset('swim.v.01')   \n",
       "14        Synset('girl.n.01')        Synset('walk.v.01')   \n",
       "16  Synset('male_child.n.01')        Synset('swim.v.01')   \n",
       "19  Synset('male_child.n.01')        Synset('walk.v.01')   \n",
       "21       Synset('woman.n.01')        Synset('swim.v.01')   \n",
       "24       Synset('woman.n.01')        Synset('walk.v.01')   \n",
       "25        Synset('walk.v.01')         Synset('man.n.01')   \n",
       "27        Synset('walk.v.01')        Synset('girl.n.01')   \n",
       "28        Synset('walk.v.01')  Synset('male_child.n.01')   \n",
       "29        Synset('walk.v.01')       Synset('woman.n.01')   \n",
       "\n",
       "                      lcs  path_sim   lch_sim   wup_sim   lin_sim  \n",
       "13   Synset('woman.n.01')  0.500000  2.944439  0.631579  0.906780  \n",
       "22   Synset('woman.n.01')  0.500000  2.944439  0.947368  0.906780  \n",
       "9   Synset('travel.v.01')  0.333333  2.159484  0.333333  0.491005  \n",
       "26  Synset('travel.v.01')  0.333333  2.159484  0.333333  0.491005  \n",
       "12  Synset('person.n.01')  0.166667  1.845827  0.631579  0.292728  \n",
       "17  Synset('person.n.01')  0.166667  1.845827  0.631579  0.292728  \n",
       "18  Synset('person.n.01')  0.200000  2.028148  0.666667  0.318423  \n",
       "23  Synset('person.n.01')  0.200000  2.028148  0.666667  0.318423  \n",
       "2     Synset('male.n.02')  0.333333  2.538974  0.666667  0.729472  \n",
       "15    Synset('male.n.02')  0.333333  2.538974  0.666667  0.729472  \n",
       "1    Synset('adult.n.01')  0.250000  2.251292  0.631579  0.713511  \n",
       "3    Synset('adult.n.01')  0.333333  2.538974  0.666667  0.787084  \n",
       "10   Synset('adult.n.01')  0.250000  2.251292  0.631579  0.713511  \n",
       "20   Synset('adult.n.01')  0.333333  2.538974  0.666667  0.787084  \n",
       "0                    None  0.100000       NaN  0.181818       NaN  \n",
       "4                    None  0.100000       NaN  0.181818       NaN  \n",
       "5                    None  0.100000       NaN  0.181818       NaN  \n",
       "6                    None  0.090909       NaN  0.166667       NaN  \n",
       "7                    None  0.100000       NaN  0.181818       NaN  \n",
       "8                    None  0.100000       NaN  0.181818       NaN  \n",
       "11                   None  0.090909       NaN  0.166667       NaN  \n",
       "14                   None  0.090909       NaN  0.166667       NaN  \n",
       "16                   None  0.100000       NaN  0.181818       NaN  \n",
       "19                   None  0.100000       NaN  0.181818       NaN  \n",
       "21                   None  0.100000       NaN  0.181818       NaN  \n",
       "24                   None  0.100000       NaN  0.181818       NaN  \n",
       "25                   None  0.100000       NaN  0.181818       NaN  \n",
       "27                   None  0.090909       NaN  0.166667       NaN  \n",
       "28                   None  0.100000       NaN  0.181818       NaN  \n",
       "29                   None  0.100000       NaN  0.181818       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_path_similarity(syn1, syn2):\n",
    "    return syn1.path_similarity(syn2)\n",
    "\n",
    "def get_lch_similarity(syn1, syn2):\n",
    "    try:\n",
    "        return syn1.lch_similarity(syn2)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def get_wup_similarity(syn1, syn2):\n",
    "    try:\n",
    "        return syn1.wup_similarity(syn2)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def get_lin_similarity(syn1, syn2):\n",
    "    try:\n",
    "        return syn1.lin_similarity(syn2, brown_ic)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "df['path_sim'] = df.apply(lambda x: x['word1'].path_similarity(x['word2']), axis=1)\n",
    "df['lch_sim'] = df.apply(lambda x: get_lch_similarity(x['word1'], x['word2']), axis=1)\n",
    "df['wup_sim'] = df.apply(lambda x: get_wup_similarity(x['word1'], x['word2']), axis=1)\n",
    "df['lin_sim'] = df.apply(lambda x: get_lin_similarity(x['word1'], x['word2']), axis=1)\n",
    "\n",
    "df.sort_values(by='lcs', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned at the begining of this work, not all the similarities are between 0 and 1. This is why the values of Leacock and Chodorow simmilarity are normalized so that they are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>lcs</th>\n",
       "      <th>path_sim</th>\n",
       "      <th>lch_sim</th>\n",
       "      <th>wup_sim</th>\n",
       "      <th>lin_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.798193</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.906780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.798193</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.906780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('travel.v.01')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.585404</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.491005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('travel.v.01')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.585404</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.491005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.292728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.292728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.549801</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.318423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('person.n.01')</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.549801</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.318423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('male.n.02')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.688278</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.729472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('male.n.02')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.688278</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.729472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.610292</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.713511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.688278</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.787084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.610292</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.713511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('adult.n.01')</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.688278</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.787084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('swim.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('man.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('male_child.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Synset('walk.v.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>None</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        word1                      word2  \\\n",
       "13        Synset('girl.n.01')       Synset('woman.n.01')   \n",
       "22       Synset('woman.n.01')        Synset('girl.n.01')   \n",
       "9         Synset('swim.v.01')        Synset('walk.v.01')   \n",
       "26        Synset('walk.v.01')        Synset('swim.v.01')   \n",
       "12        Synset('girl.n.01')  Synset('male_child.n.01')   \n",
       "17  Synset('male_child.n.01')        Synset('girl.n.01')   \n",
       "18  Synset('male_child.n.01')       Synset('woman.n.01')   \n",
       "23       Synset('woman.n.01')  Synset('male_child.n.01')   \n",
       "2          Synset('man.n.01')  Synset('male_child.n.01')   \n",
       "15  Synset('male_child.n.01')         Synset('man.n.01')   \n",
       "1          Synset('man.n.01')        Synset('girl.n.01')   \n",
       "3          Synset('man.n.01')       Synset('woman.n.01')   \n",
       "10        Synset('girl.n.01')         Synset('man.n.01')   \n",
       "20       Synset('woman.n.01')         Synset('man.n.01')   \n",
       "0          Synset('man.n.01')        Synset('swim.v.01')   \n",
       "4          Synset('man.n.01')        Synset('walk.v.01')   \n",
       "5         Synset('swim.v.01')         Synset('man.n.01')   \n",
       "6         Synset('swim.v.01')        Synset('girl.n.01')   \n",
       "7         Synset('swim.v.01')  Synset('male_child.n.01')   \n",
       "8         Synset('swim.v.01')       Synset('woman.n.01')   \n",
       "11        Synset('girl.n.01')        Synset('swim.v.01')   \n",
       "14        Synset('girl.n.01')        Synset('walk.v.01')   \n",
       "16  Synset('male_child.n.01')        Synset('swim.v.01')   \n",
       "19  Synset('male_child.n.01')        Synset('walk.v.01')   \n",
       "21       Synset('woman.n.01')        Synset('swim.v.01')   \n",
       "24       Synset('woman.n.01')        Synset('walk.v.01')   \n",
       "25        Synset('walk.v.01')         Synset('man.n.01')   \n",
       "27        Synset('walk.v.01')        Synset('girl.n.01')   \n",
       "28        Synset('walk.v.01')  Synset('male_child.n.01')   \n",
       "29        Synset('walk.v.01')       Synset('woman.n.01')   \n",
       "\n",
       "                      lcs  path_sim   lch_sim   wup_sim   lin_sim  \n",
       "13   Synset('woman.n.01')  0.500000  0.798193  0.631579  0.906780  \n",
       "22   Synset('woman.n.01')  0.500000  0.798193  0.947368  0.906780  \n",
       "9   Synset('travel.v.01')  0.333333  0.585404  0.333333  0.491005  \n",
       "26  Synset('travel.v.01')  0.333333  0.585404  0.333333  0.491005  \n",
       "12  Synset('person.n.01')  0.166667  0.500376  0.631579  0.292728  \n",
       "17  Synset('person.n.01')  0.166667  0.500376  0.631579  0.292728  \n",
       "18  Synset('person.n.01')  0.200000  0.549801  0.666667  0.318423  \n",
       "23  Synset('person.n.01')  0.200000  0.549801  0.666667  0.318423  \n",
       "2     Synset('male.n.02')  0.333333  0.688278  0.666667  0.729472  \n",
       "15    Synset('male.n.02')  0.333333  0.688278  0.666667  0.729472  \n",
       "1    Synset('adult.n.01')  0.250000  0.610292  0.631579  0.713511  \n",
       "3    Synset('adult.n.01')  0.333333  0.688278  0.666667  0.787084  \n",
       "10   Synset('adult.n.01')  0.250000  0.610292  0.631579  0.713511  \n",
       "20   Synset('adult.n.01')  0.333333  0.688278  0.666667  0.787084  \n",
       "0                    None  0.100000       NaN  0.181818       NaN  \n",
       "4                    None  0.100000       NaN  0.181818       NaN  \n",
       "5                    None  0.100000       NaN  0.181818       NaN  \n",
       "6                    None  0.090909       NaN  0.166667       NaN  \n",
       "7                    None  0.100000       NaN  0.181818       NaN  \n",
       "8                    None  0.100000       NaN  0.181818       NaN  \n",
       "11                   None  0.090909       NaN  0.166667       NaN  \n",
       "14                   None  0.090909       NaN  0.166667       NaN  \n",
       "16                   None  0.100000       NaN  0.181818       NaN  \n",
       "19                   None  0.100000       NaN  0.181818       NaN  \n",
       "21                   None  0.100000       NaN  0.181818       NaN  \n",
       "24                   None  0.100000       NaN  0.181818       NaN  \n",
       "25                   None  0.100000       NaN  0.181818       NaN  \n",
       "27                   None  0.090909       NaN  0.166667       NaN  \n",
       "28                   None  0.100000       NaN  0.181818       NaN  \n",
       "29                   None  0.100000       NaN  0.181818       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_value = np.log(2 * max_depth)\n",
    "\n",
    "df_norm = df.copy()\n",
    "df_norm['lch_sim'] = df_norm['lch_sim'] / norm_value\n",
    "df_norm = df_norm.loc[:, df.columns]\n",
    "df_norm = df_norm.sort_values(by='lcs', ascending=False)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be observed from the table above, most of the LCS are missing. This is because the synsets are not related in the Wordnet hierarchy, i.e., verbs and nouns don't have any common parent in the ontology.\n",
    "\n",
    "This is why, also, most of the similarity measures couldn't be computed. However, some of them introduce a ghost node common for all the hierarchies so that some sort of value can be computed. This  is the case of the Path Similarity and the Wu Palmer.\n",
    "\n",
    "In addition to this, it is remarkable that Wu Palmer is not always symmetric. This is because the depth of the LCS is calculated from the first synset to the second one. This is why the similarity values are not always the same.\n",
    "\n",
    "The Wu-Palmer similarity measure is not symmetric due to the way it is calculated and the nature of the information used to measure semantic similarity between two words. The Wu-Palmer similarity is based on the idea that two words are more similar if they share a common ancestor in the hierarchy of concepts in a semantic network, such as WordNet, a lexical database that organizes words into a hierarchical structure.\n",
    "\n",
    "The asymmetry arises from how the Least Common Subsumer (LCS) is chosen. The LCS is the closest common ancestor to both words in the hierarchy. Since the closest common ancestor depends on the relative position of the words in the hierarchy, the result can be different when the words $w_1$ and $w_2$ are swapped. Therefore, the Wu-Palmer similarity is not symmetric because $\\text{sim}(w_1, w_2)$ is not necessarily equal to $\\text{sim}(w_2, w_1)$.\n",
    "\n",
    "In summary, the asymmetry in the Wu-Palmer similarity measure is due to the dependence on the relative position of words in the hierarchy and how the closest common ancestor is selected to calculate semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>lcs</th>\n",
       "      <th>path_sim</th>\n",
       "      <th>lch_sim</th>\n",
       "      <th>wup_sim</th>\n",
       "      <th>lin_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798193</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.90678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>Synset('girl.n.01')</td>\n",
       "      <td>Synset('woman.n.01')</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.798193</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.90678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word1                 word2                   lcs  \\\n",
       "13   Synset('girl.n.01')  Synset('woman.n.01')  Synset('woman.n.01')   \n",
       "22  Synset('woman.n.01')   Synset('girl.n.01')  Synset('woman.n.01')   \n",
       "\n",
       "    path_sim   lch_sim   wup_sim  lin_sim  \n",
       "13       0.5  0.798193  0.631579  0.90678  \n",
       "22       0.5  0.798193  0.947368  0.90678  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the asymetric behavior\n",
    "df_norm.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of synsets proportions a way to take into account the semantic meaning of the words. In this work, four different measures have been calculated.\n",
    "\n",
    "Each of them has its advantages and disadvantages.\n",
    "\n",
    "1. **Path Similarity:**\n",
    "   - **Advantages:**\n",
    "     - Simple and easy to understand.\n",
    "     - It provides a straightforward measure of similarity based on the length of the shortest path between two concepts in the hierarchical structure.\n",
    "   - **Disadvantages:**\n",
    "     - Ignores the depth of the hierarchy, so it may not give accurate results when dealing with very shallow or very deep hierarchies.\n",
    "     - Fails to capture the nuances of word relationships beyond the number of edges in the hierarchy.\n",
    "\n",
    "2. **Leacock-Chodorow Similarity:**\n",
    "   - **Advantages:**\n",
    "     - It takes into account the depth of the hierarchy by using a logarithmic function.\n",
    "     - Provides a more refined similarity measure than simple Path Similarity.\n",
    "   - **Disadvantages:**\n",
    "     - Still relatively simple and may not capture all aspects of word similarity, especially when dealing with highly specific or general terms.\n",
    "     - The logarithmic function might not be ideal for all applications and may require tuning.\n",
    "\n",
    "3. **Wu-Palmer Similarity:**\n",
    "   - **Advantages:**\n",
    "     - Considers the depth of the least common subsumer (LCS) in the hierarchy, providing a more refined measure of similarity.\n",
    "     - Tends to produce better results than Path Similarity and Leacock-Chodorow in various applications.\n",
    "   - **Disadvantages:**\n",
    "     - Not symmetric, meaning that $(\\text{sim}(w_1, w_2))$ is not necessarily equal to $(\\text{sim}(w_2, w_1))$.\n",
    "     - May not work well when dealing with highly specific terms with deep hierarchies.\n",
    "\n",
    "4. **Lin Similarity:**\n",
    "   - **Advantages:**\n",
    "     - Takes into account not only the depth of the hierarchy but also the information content of the terms.\n",
    "     - Often produces more accurate similarity scores than the previous measures.\n",
    "   - **Disadvantages:**\n",
    "     - Requires additional information content, which can be challenging to estimate accurately.\n",
    "     - May be computationally more expensive than the simpler measures.\n",
    "\n",
    "In summary, each of these similarity measures has its own strengths and weaknesses. The choice of which one to use depends on the specific application, the characteristics of the data, and the availability of additional resources (such as information content estimates). Researchers and practitioners often experiment with different measures to determine which one works best for their particular use case.\n",
    "\n",
    "This is why, it makes sense to consider that, in case of having the statistical information needed, Lin Similarity looks the most accurate and trustworthy. Otherwise, Leacock-Chodorow and Wu-Palmer are good candidates. However, the lack of symmetry of the latter make Leacock-Chodorow the most sensible choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
